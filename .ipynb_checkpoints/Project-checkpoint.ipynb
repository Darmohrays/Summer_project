{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import random\n",
    "from utils import get_chars, get_words, save_img, resize\n",
    "from highlight import HighlightWords\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img, figsize=(20, 20)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(path, process=True):\n",
    "    filenames = os.listdir(path)\n",
    "    if process:\n",
    "        imgs = [process_img(path + name) for name in filenames if not 'ipynb' in name]\n",
    "    else:\n",
    "        imgs = [cv2.imread(path + name) for name in filenames if not 'ipynb' in name]\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, imgs, words):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    imgs = []\n",
    "    for i, example in enumerate(words):\n",
    "        for word, (x, y, w, h) in enumerate(example):\n",
    "            temp_img = imgs[i][y:y+h, x:x+w]\n",
    "#             print(temp_img)\n",
    "            temp_img = resize(imgs[i], (x, y, w, h))\n",
    "            temp_img = normalize_images(temp_img)\n",
    "            \n",
    "            if predicted == word:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                \n",
    "    accuracy = correct / (correct+wrong)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self._path = 'course_project/train/{}/{}.jpg'\n",
    "        self._font_names = [ name for name in os.listdir('course_project/train/') if '.' not in name]\n",
    "        self._indxs = np.zeros((49, 88))\n",
    "        self._indxs[:] = np.arange(88)\n",
    "        self._last_batch = None\n",
    "        \n",
    "    def gen_batches(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        for row in range(49):\n",
    "            self._indxs[row] = np.random.randint(49, size=88)\n",
    "        self._last_batch = 0\n",
    "    \n",
    "    def get_batch(self):\n",
    "        X = np.zeros((88, 28, 28, 1))\n",
    "        y = np.zeros((88, 62))\n",
    "\n",
    "        indx = 0\n",
    "        for j, val in enumerate(self._indxs[self._last_batch+1]):\n",
    "            path = self._path.format(self._font_names[int(val)], alphabet[j])\n",
    "            X[indx] = read_one_img(path).reshape((28, 28, 1))\n",
    "            y[indx][temp[j]] = 1\n",
    "                \n",
    "            indx += 1\n",
    "        self._last_batch += 1\n",
    "        \n",
    "        indxs = np.random.permutation(88)\n",
    "        \n",
    "        return X[indxs], y[indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words1(img):\n",
    "    maxs = np.max(img, axis=1) # Take \n",
    "    indxs_y = np.where(maxs[:-1] != maxs[1:])[0]\n",
    "    cordinates = [] # (x, y, w, h)\n",
    "    for indx_y in range(0, len(indxs_y)-1, 2):\n",
    "        row = img[indxs_y[indx_y]:indxs_y[indx_y+1]]\n",
    "#         print(indxs_y[indx_y+1] - indxs_y[indx_y])\n",
    "        kernel_x = (indxs_y[indx_y+1] - indxs_y[indx_y]) % 20\n",
    "#         print(kernel_x)\n",
    "        kernel = np.ones((2, min(kernel_x+2+kernel_x//2, 12)), np.uint8)\n",
    "        dilated = cv2.dilate(row, kernel, iterations=1)\n",
    "        maxs1 = np.max(dilated, axis=0)\n",
    "        indxs_x = np.where(maxs1[:-1] != maxs1[1:])[0]\n",
    "        for indx_x in range(0, len(indxs_x)-1, 2):\n",
    "            cordinates.append((\n",
    "                indxs_x[indx_x],\n",
    "                indxs_y[indx_y],\n",
    "                indxs_x[indx_x+1] - indxs_x[indx_x],\n",
    "                indxs_y[indx_y+1] - indxs_y[indx_y]\n",
    "            ))\n",
    "            \n",
    "    return cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'course_project/test/x_test/'\n",
    "filenames = os.listdir(path)\n",
    "imgs = read_imgs(path)\n",
    "originals = read_imgs(path, process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 19.3 ms, total: 170 ms\n",
      "Wall time: 170 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = []\n",
    "# chars = []\n",
    "for img in imgs:\n",
    "    temp_words = get_words1(img)\n",
    "#     chars.append(get_chars(img, temp_words))\n",
    "    words.append(temp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = 'course_project/tested/'\n",
    "for i, item in enumerate(words):\n",
    "    temp_img = originals[i].copy()\n",
    "    for (x, y, w, h) in item:\n",
    "        cv2.rectangle(temp_img, (x, y), (x+w, y+h), (0, 255, 0))\n",
    "        save_img(path_to_save, temp_img, str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e0a65ede7019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalize_images' is not defined"
     ]
    }
   ],
   "source": [
    "n = 23\n",
    "# word = 23\n",
    "word = 28\n",
    "x, y, w, h = words[n][word]\n",
    "temp = resize(imgs[n], (x, y, w, h))\n",
    "temp = normalize_images(temp)\n",
    "plt.imshow(np.reshape(temp, (28, 28)), cmap='gray')\n",
    "temp = np.reshape(temp, (1, 28, 28, 1))\n",
    "print('Predicted: {}'.format(alphabet2[np.argmax(model.predict(temp))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 23\n",
    "# word = 23\n",
    "word = 78\n",
    "x, y, w, h = words[n][word]\n",
    "temp = resize(imgs[n], (x, y, w, h))\n",
    "temp = normalize_images(temp)\n",
    "plt.imshow(np.reshape(temp, (28, 28)), cmap='gray')\n",
    "temp = np.reshape(temp, (1, 28, 28, 1))\n",
    "print('Predicted: {}'.format(alphabet2[np.argmax(model.predict(temp))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
