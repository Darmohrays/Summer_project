{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import random\n",
    "from utils import get_chars, get_words\n",
    "from highlight import HighlightWords\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img, figsize=(20, 20)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(path, process=True):\n",
    "    filenames = os.listdir(path)\n",
    "    if process:\n",
    "        imgs = [process_img(path + name) for name in filenames if '.jpg' in name or '.png' in name]\n",
    "    else:\n",
    "        imgs = [cv2.imread(path + name) for name in filenames if '.jpg' in name or '.png' in name]\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_alphabet():\n",
    "    small = [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "    big = [chr(i)+'_' for i in range(ord('A'), ord('Z')+1)]\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    alphabet = flatten(zip(big, small))\n",
    "    symbols = ['point', 'dash', 'comma', '!', '?', 'colon', 'semicolon', '>', \n",
    "               '<', 'equals', 'ampersant', 'hash', 'dollar', 'percent', '^',\n",
    "               'and', 'asterics', 'round_open', 'round_close',\n",
    "              'plus', 'backslash', 'slash', 'square_open', 'square_close', 'curly_open', 'curly_close']\n",
    "    numbers = range(10)\n",
    "    for symbol in symbols:\n",
    "        alphabet.append(symbol)\n",
    "    for number in numbers:\n",
    "        alphabet.append(number)\n",
    "    \n",
    "    return alphabet\n",
    "alphabet = gen_alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indxs_to_alphabet():\n",
    "    alphabet = gen_alphabet()\n",
    "    res = []\n",
    "    indx = 0\n",
    "    for i in range(len(alphabet)):\n",
    "        if i <= 51:\n",
    "            if not i % 2:\n",
    "                res.append(indx)\n",
    "                res.append(indx)\n",
    "                indx += 1\n",
    "        else:\n",
    "            res.append(indx)\n",
    "            indx += 1\n",
    "    \n",
    "    alphabet2 = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "    symbols = ['point', 'dash', 'comma', '!', '?', 'colon', 'semicolon', '>', \n",
    "                   '<', 'equals', 'ampersant', 'hash', 'dollar', 'percent', '^',\n",
    "                   'and', 'asterics', 'round_open', 'round_close',\n",
    "                  'plus', 'backslash', 'slash', 'square_open', 'square_close', 'curly_open', 'curly_close']\n",
    "    numbers = range(10)\n",
    "    for symbol in symbols:\n",
    "        alphabet2.append(symbol)\n",
    "    for number in numbers:\n",
    "        alphabet2.append(number)\n",
    "    \n",
    "    return res, alphabet2\n",
    "\n",
    "res, alphabet2 = indxs_to_alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    H, W = 28, 28\n",
    "    images = np.reshape(images, (-1, H * W))\n",
    "    numerator = images - np.expand_dims(np.mean(images, 1), 1)\n",
    "    denominator = np.expand_dims(np.std(images, 1), 1)\n",
    "    return np.reshape(numerator / (denominator + 1e-7), (-1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, cordinates):\n",
    "    [x, y, w, h] = cordinates\n",
    "    temp_img = img[y:y+h, x:x+w]\n",
    "    \n",
    "    max_ = max(w, h)\n",
    "    temp_img = cv2.copyMakeBorder(temp_img, (max_-h)//2, (max_-h)//2, (max_-w)//2, (max_-w)//2,\n",
    "                                  cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    \n",
    "    resized = cv2.resize(temp_img, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, imgs, words):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    imgs = []\n",
    "    for i, example in enumerate(words):\n",
    "        for word, (x, y, w, h) in enumerate(example):\n",
    "            temp_img = imgs[i][y:y+h, x:x+w]\n",
    "#             print(temp_img)\n",
    "            temp_img = resize(imgs[i], (x, y, w, h))\n",
    "            temp_img = normalize_images(temp_img)\n",
    "            \n",
    "            if predicted == word:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                \n",
    "    accuracy = correct / (correct+wrong)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self._path = 'course_project/train/{}/{}.jpg'\n",
    "        self._font_names = [ name for name in os.listdir('course_project/train/') if '.' not in name]\n",
    "        self._indxs = np.zeros((49, 88))\n",
    "        self._indxs[:] = np.arange(88)\n",
    "        self._last_batch = None\n",
    "        \n",
    "    def gen_batches(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        for row in range(49):\n",
    "            self._indxs[row] = np.random.randint(49, size=88)\n",
    "        self._last_batch = 0\n",
    "    \n",
    "    def get_batch(self):\n",
    "        X = np.zeros((88, 28, 28, 1))\n",
    "        y = np.zeros((88, 62))\n",
    "\n",
    "        indx = 0\n",
    "        for j, val in enumerate(self._indxs[self._last_batch+1]):\n",
    "            path = self._path.format(self._font_names[int(val)], alphabet[j])\n",
    "            X[indx] = read_one_img(path).reshape((28, 28, 1))\n",
    "            y[indx][temp[j]] = 1\n",
    "                \n",
    "            indx += 1\n",
    "        self._last_batch += 1\n",
    "        \n",
    "        indxs = np.random.permutation(88)\n",
    "        \n",
    "        return X[indxs], y[indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 15:56:33.960611 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 15:56:34.050845 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0826 15:56:34.121949 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 15:56:34.122524 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0826 15:56:34.123014 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0826 15:56:34.147785 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0826 15:56:54.457487 4520105408 deprecation_wrapper.py:119] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 15:56:54.643493 4520105408 deprecation.py:323] From /Users/svatoslavdarmograj/Documents/ml/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('course_project/model_more_classes2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'course_project/alphabet/'\n",
    "imgs = read_imgs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 ms, sys: 1.94 ms, total: 44.5 ms\n",
      "Wall time: 53.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = []\n",
    "# chars = []\n",
    "for img in imgs:\n",
    "    temp_words = get_words(img)\n",
    "#     chars.append(get_chars(img, temp_words))\n",
    "    words.append(temp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet2 = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "symbols = [\".\", \"-\", \",\", \"!\", \"?\", \":\", \";\", \">\", \n",
    "               \"<\", \"=\", \"@\", \"#\", \"$\", \"%\", \"^\",\n",
    "               \"&\", \"*\", \"(\", \")\",\n",
    "              \"+\", \"\\\\\", \"/\", \"[\", \"]\", \"{\", \"}\"]\n",
    "numbers = range(10)\n",
    "for symbol in symbols:\n",
    "    alphabet2.append(symbol)\n",
    "for number in numbers:\n",
    "    alphabet2.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_save = 'course_project/train/{}/'\n",
    "# filenames = [name for name in os.listdir('course_project/alphabet/') if 'DS' not in name]\n",
    "# for i, font in enumerate(words):\n",
    "#     for word, cordinates in zip(alphabet, font):\n",
    "#         img = resize(imgs[i], cordinates)\n",
    "#         save_img(path_to_save.format(filenames[i][:-4]), img, str(word)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: O\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 23\n",
    "# word = 23\n",
    "word = 28\n",
    "x, y, w, h = words[n][word]\n",
    "temp = resize(imgs[n], (x, y, w, h))\n",
    "temp = normalize_images(temp)\n",
    "plt.imshow(np.reshape(temp, (28, 28)), cmap='gray')\n",
    "temp = np.reshape(temp, (1, 28, 28, 1))\n",
    "print('Predicted: {}'.format(alphabet2[np.argmax(model.predict(temp))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 23\n",
    "# word = 23\n",
    "word = 78\n",
    "x, y, w, h = words[n][word]\n",
    "temp = resize(imgs[n], (x, y, w, h))\n",
    "temp = normalize_images(temp)\n",
    "plt.imshow(np.reshape(temp, (28, 28)), cmap='gray')\n",
    "temp = np.reshape(temp, (1, 28, 28, 1))\n",
    "print('Predicted: {}'.format(alphabet2[np.argmax(model.predict(temp))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighlightWords:\n",
    "    def __init__(self, model):\n",
    "#         self._model = load_model('course_project/model_more_classes2.h5');\n",
    "        self._model = model\n",
    "        self._orig_img = None\n",
    "        self._text = ''\n",
    "        self._bboxes = None\n",
    "        self._most_frequent_word = None\n",
    "#         self._alphabet = gen_alphabet()\n",
    "        self._alphabet = alphabet2\n",
    "        print('Initialized')\n",
    "        \n",
    "    def _find_most_frequent(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_bboxes(self):\n",
    "        words = get_words(self._thresholded_img)\n",
    "        chars = get_chars(self._thresholded_img, words)\n",
    "        self._bboxes = chars\n",
    "\n",
    "    def _get_prediction(self):\n",
    "        for i, word in enumerate(self._bboxes.values()):\n",
    "            print('Word: {}'.format(i))\n",
    "            for j, character_bbox in enumerate(word['cordinates']):\n",
    "                img = resize(self._thresholded_img, character_bbox)\n",
    "                img = normalize_images(img)\n",
    "\n",
    "                img = img.reshape((1, 28, 28, 1))\n",
    "                prediction = model.predict(img)\n",
    "                decoded = self._alphabet[np.argmax(prediction)]\n",
    "                \n",
    "                self._text += str(decoded)\n",
    "                \n",
    "            self._text += ' '\n",
    "            \n",
    "            \n",
    "    def fit(self, img):\n",
    "        self._orig_img = img\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        self._thresholded_img = img\n",
    "        self._get_bboxes()\n",
    "        self._get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Word: 0\n",
      "Word: 1\n",
      "Word: 2\n",
      "Word: 3\n",
      "Word: 4\n",
      "Word: 5\n",
      "Word: 6\n",
      "Word: 7\n",
      "Word: 8\n",
      "Word: 9\n",
      "Word: 10\n",
      "Word: 11\n",
      "Word: 12\n",
      "Word: 13\n",
      "Word: 14\n",
      "Word: 15\n",
      "Word: 16\n",
      "Word: 17\n",
      "Word: 18\n",
      "Word: 19\n",
      "Word: 20\n",
      "Word: 21\n",
      "Word: 22\n",
      "Word: 23\n",
      "Word: 24\n",
      "Word: 25\n",
      "Word: 26\n",
      "Word: 27\n",
      "Word: 28\n",
      "Word: 29\n",
      "Word: 30\n",
      "Word: 31\n",
      "Word: 32\n",
      "Word: 33\n",
      "Word: 34\n",
      "Word: 35\n",
      "Word: 36\n",
      "Word: 37\n",
      "Word: 38\n",
      "Word: 39\n",
      "Word: 40\n",
      "Word: 41\n",
      "Word: 42\n",
      "Word: 43\n",
      "Word: 44\n",
      "Word: 45\n",
      "Word: 46\n",
      "Word: 47\n",
      "Word: 48\n",
      "Word: 49\n",
      "Word: 50\n",
      "Word: 51\n",
      "Word: 52\n",
      "Word: 53\n",
      "Word: 54\n",
      "Word: 55\n",
      "Word: 56\n",
      "Word: 57\n",
      "Word: 58\n",
      "Word: 59\n",
      "Word: 60\n",
      "Word: 61\n",
      "Word: 62\n",
      "Word: 63\n",
      "Word: 64\n",
      "Word: 65\n",
      "Word: 66\n",
      "Word: 67\n",
      "Word: 68\n",
      "Word: 69\n",
      "Word: 70\n",
      "Word: 71\n",
      "Word: 72\n",
      "Word: 73\n",
      "Word: 74\n",
      "Word: 75\n",
      "Word: 76\n",
      "Word: 77\n",
      "Word: 78\n",
      "Word: 79\n",
      "Word: 80\n",
      "Word: 81\n",
      "Word: 82\n",
      "Word: 83\n",
      "Word: 84\n",
      "Word: 85\n",
      "Word: 86\n",
      "Word: 87\n",
      "Word: 88\n",
      "Word: 89\n",
      "Word: 90\n",
      "Word: 91\n",
      "Word: 92\n",
      "Word: 93\n",
      "Word: 94\n",
      "Word: 95\n",
      "Word: 96\n",
      "Word: 97\n",
      "Word: 98\n",
      "Word: 99\n",
      "Word: 100\n",
      "Word: 101\n",
      "Word: 102\n",
      "Word: 103\n",
      "Word: 104\n",
      "Word: 105\n",
      "Word: 106\n",
      "Word: 107\n",
      "Word: 108\n",
      "Word: 109\n",
      "Word: 110\n",
      "Word: 111\n",
      "Word: 112\n",
      "Word: 113\n",
      "Word: 114\n",
      "Word: 115\n",
      "Word: 116\n",
      "Word: 117\n",
      "Word: 118\n",
      "Word: 119\n",
      "Word: 120\n",
      "Word: 121\n",
      "Word: 122\n",
      "Word: 123\n",
      "Word: 124\n",
      "Word: 125\n",
      "Word: 126\n",
      "Word: 127\n",
      "Word: 128\n",
      "Word: 129\n",
      "Word: 130\n",
      "Word: 131\n",
      "Word: 132\n",
      "Word: 133\n",
      "Word: 134\n",
      "Word: 135\n",
      "Word: 136\n",
      "Word: 137\n",
      "Word: 138\n",
      "Word: 139\n",
      "Word: 140\n",
      "Word: 141\n",
      "Word: 142\n",
      "Word: 143\n",
      "Word: 144\n",
      "Word: 145\n",
      "Word: 146\n",
      "Word: 147\n",
      "Word: 148\n",
      "Word: 149\n",
      "Word: 150\n",
      "Word: 151\n",
      "Word: 152\n",
      "Word: 153\n",
      "Word: 154\n",
      "Word: 155\n",
      "Word: 156\n",
      "Word: 157\n",
      "Word: 158\n",
      "Word: 159\n",
      "Word: 160\n",
      "Word: 161\n",
      "Word: 162\n",
      "Word: 163\n",
      "Word: 164\n",
      "Word: 165\n",
      "CPU times: user 1min 7s, sys: 4.85 s, total: 1min 12s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_photo = plt.imread('test_photos/5.jpg')\n",
    "# plot_img(test_photo)\n",
    "hw = HighlightWords(model)\n",
    "hw.fit(test_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
